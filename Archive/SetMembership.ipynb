{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines two **abstract classes**: the first represents a set and basic insert/search operations on it. You will need to impement this API four times, to implement (1) sequential search, (2) binary search tree, (3) balanced search tree, and (4) bloom filter. The second defines the synthetic data generator you will need to implement as part of your experimental framework. <br><br>**Do NOT modify the next cell** - use the dedicated cells further below for your implementation instead. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL\n",
    "\n",
    "from abc import ABC, abstractmethod  \n",
    "\n",
    "# abstract class to represent a set and its insert/search operations\n",
    "class AbstractSet(ABC):\n",
    "    \n",
    "    # constructor\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass           \n",
    "        \n",
    "    # inserts \"element\" in the set\n",
    "    # returns \"True\" after successful insertion, \"False\" if the element is already in the set\n",
    "    # element : str\n",
    "    # inserted : bool\n",
    "    @abstractmethod\n",
    "    def insertElement(self, element):     \n",
    "        inserted = False\n",
    "        return inserted   \n",
    "    \n",
    "    # checks whether \"element\" is in the set\n",
    "    # returns \"True\" if it is, \"False\" otherwise\n",
    "    # element : str\n",
    "    # found : bool\n",
    "    @abstractmethod\n",
    "    def searchElement(self, element):\n",
    "        found = False\n",
    "        return found    \n",
    "    \n",
    "    \n",
    "    \n",
    "# abstract class to represent a synthetic data generator\n",
    "class AbstractTestDataGenerator(ABC):\n",
    "    \n",
    "    # constructor\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass           \n",
    "        \n",
    "    # creates and returns a list of length \"size\" of strings\n",
    "    # size : int\n",
    "    # data : list<str>\n",
    "    @abstractmethod\n",
    "    def generateData(self, size):     \n",
    "        data = [\"\"]*size\n",
    "        return data   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to define any auxiliary data structure and python function you may need. Leave the implementation of the main API to the next code cells instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD AUXILIARY DATA STRUCTURE DEFINITIONS AND HELPER CODE HERE\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class RB_Node(Node):\n",
    "    RED = True\n",
    "    BLACK = False\n",
    "\n",
    "    def __init__(self, value, colour):\n",
    "        super().__init__(value)\n",
    "        self.colour = colour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **sequential search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialSearchSet(AbstractSet):\n",
    "    def __init__(self):\n",
    "        self.set = []      \n",
    "     \n",
    "    def insertElement(self, element):\n",
    "        if self.searchElement(element) is False:\n",
    "            self.set.append(element)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def searchElement(self, element):\n",
    "        for member in self.set:\n",
    "            if member == element:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **binary search tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarySearchTreeSet(AbstractSet):\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def insertElement(self, element):\n",
    "        if not self.root:\n",
    "            self.root = Node(element)\n",
    "            return True\n",
    "        else:\n",
    "            current = self.root\n",
    "            while current:\n",
    "                if current.value == element:\n",
    "                    return False\n",
    "                elif current.value > element:\n",
    "                    if not current.left:\n",
    "                        current.left = Node(element)\n",
    "                        return True\n",
    "                    current = current.left\n",
    "                elif current.value < element:\n",
    "                    if not current.right:\n",
    "                        current.right = Node(element)\n",
    "                        return True\n",
    "                    current = current.right\n",
    "        return False\n",
    "\n",
    "    def searchElement(self, element):\n",
    "        current = self.root\n",
    "        while current:\n",
    "            if current.value == element:\n",
    "                return True\n",
    "            elif current.value > element:\n",
    "                current = current.left\n",
    "            elif current.value < element:\n",
    "                current = current.right\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **balanced search tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedSearchTreeSet(AbstractSet):\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "\n",
    "    @staticmethod\n",
    "    def is_red(node):\n",
    "        if node is None:\n",
    "            return False\n",
    "        return node.colour == RB_Node.RED\n",
    "\n",
    "    @staticmethod\n",
    "    def rotate_left(node):\n",
    "        x = node.right\n",
    "        node.right = x.left\n",
    "        x.left = node\n",
    "        x.colour = node.colour\n",
    "        node.colour = RB_Node.RED\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def rotate_right(node):\n",
    "        x = node.left\n",
    "        node.left = x.right\n",
    "        x.right = node\n",
    "        x.colour = node.colour\n",
    "        node.colour = RB_Node.RED\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def flip_colours(node):\n",
    "        node.colour = RB_Node.RED\n",
    "        node.left.colour = RB_Node.BLACK\n",
    "        node.right.colour = RB_Node.BLACK\n",
    "    \n",
    "    def insertElement(self, element):\n",
    "        self.root, inserted = self._insertElement(self.root, element)\n",
    "        self.root.colour = RB_Node.BLACK\n",
    "        return inserted\n",
    "    \n",
    "    def _insertElement(self, node, element):\n",
    "        if node is None:\n",
    "            return RB_Node(element, RB_Node.RED), True\n",
    "\n",
    "        if element < node.value:\n",
    "            node.left, inserted = self._insertElement(node.left, element)\n",
    "        elif element > node.value:\n",
    "            node.right, inserted = self._insertElement(node.right, element)\n",
    "        else:\n",
    "            return node, False\n",
    "        \n",
    "        if self.is_red(node.right) and not self.is_red(node.left):\n",
    "            node = self.rotate_left(node)\n",
    "        if self.is_red(node.left) and self.is_red(node.left.left):\n",
    "            node = self.rotate_right(node)\n",
    "        if self.is_red(node.left) and self.is_red(node.right):\n",
    "            self.flip_colours(node)\n",
    "        return node, inserted    \n",
    "\n",
    "    def searchElement(self, element):     \n",
    "        return self._searchElement(self.root, element) == element\n",
    "\n",
    "    def _searchElement(self, node, element):\n",
    "        if node is None:\n",
    "            return False\n",
    "\n",
    "        if element < node.value:\n",
    "            return self._searchElement(node.left, element)\n",
    "        elif element > node.value:\n",
    "            return self._searchElement(node.right, element)\n",
    "        else:\n",
    "            return node.value   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the requested API by means of **bloom filter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "\n",
    "EXPECTED_NUM_INSERTIONS = 500000\n",
    "BITARRAY_SIZE = EXPECTED_NUM_INSERTIONS * 50\n",
    "LN2 = 0.69314718056\n",
    "\n",
    "class BloomFilterSet(AbstractSet):\n",
    "    def __init__(self, size, num_hashes=3):\n",
    "        self.size = size\n",
    "        self.num_hashes = num_hashes\n",
    "        self.bit_array = bitarray(size)\n",
    "        self.bit_array.setall(0)\n",
    "\n",
    "    def _hash(self, element):\n",
    "        hash_values = []\n",
    "        for i in range(self.num_hashes):\n",
    "            hash_value = hash(f'{element}{i}')\n",
    "            hash_values.append(hash_value % self.size)\n",
    "        return hash_values\n",
    "    \n",
    "    @staticmethod\n",
    "    def optimise_k(m, n):\n",
    "        return 1 + int(LN2 * (m / n))\n",
    "        \n",
    "    def insertElement(self, element):\n",
    "        if self.searchElement(element) is False:\n",
    "            hash_values = self._hash(element)\n",
    "            for value in hash_values:\n",
    "                self.bit_array[value] = 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def searchElement(self, element):     \n",
    "        hash_values = self._hash(element)\n",
    "        for value in hash_values:\n",
    "            if not self.bit_array[value]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to implement the **synthetic data generator** as part of your experimental framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "class TestDataGenerator(AbstractTestDataGenerator):\n",
    "    NUM_WORDS = 50000\n",
    "    MIN_LENGTH = 1\n",
    "    AV_LOW_LENGTH = 2\n",
    "    AV_HIGH_LENGTH = 6\n",
    "    MAX_LENGTH = 12\n",
    "    CONSONANTS = 'bcdfghjklmnpqrstvwxyz'\n",
    "    VOWELS = 'aeiou'\n",
    "    test_file = \"synthetic_test_search.txt\"\n",
    "    SAMPLE_INTERVAL = 200\n",
    "    test_words = set()\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def generate_word(self, scarcity=0.05):\n",
    "        limit = int(1 / scarcity)\n",
    "        roulette = random.randint(0, int(1 / scarcity))\n",
    "        if roulette == limit:\n",
    "            length = random.randint(self.AV_LOW_LENGTH, self.AV_HIGH_LENGTH)\n",
    "        else:\n",
    "            length = random.randint(self.MIN_LENGTH, self.MAX_LENGTH)\n",
    "        word = ''\n",
    "        for i in range(length):\n",
    "            if i % 2 == 1 or length == 1:\n",
    "                word += random.choice(self.VOWELS)\n",
    "            else:\n",
    "                word += random.choice(self.CONSONANTS)\n",
    "        return word\n",
    "\n",
    "    # Generate the words and put them in an array + create a test file\n",
    "    def generateData(self, size):\n",
    "        data = []\n",
    "        for i in range(size):\n",
    "            word = self.generate_word()\n",
    "            data.append(word)\n",
    "            if i % self.SAMPLE_INTERVAL == 0:\n",
    "                self.test_words.add(word)\n",
    "                self.test_words.add(self.generate_word())\n",
    "\n",
    "        test_words = list(self.test_words)\n",
    "        with open(self.test_file, 'w') as f:\n",
    "            for i in range(len(test_words)):\n",
    "                f.write(test_words[i])\n",
    "                if i <= len(test_words):\n",
    "                    f.write('\\n')\n",
    "\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cells below for the python code needed to **fully evaluate your implementations**, first on real data and subsequently on synthetic data (i.e., read data from test files / generate synthetic one, instantiate each of the 4 set implementations in turn, then thorouhgly experiment with insert/search operations and measure their performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BST\n",
      "Mean Search Time - {'BST': {0: 2.1972488441051694e-06, 2093: 1.0801650105266395e-05, 4186: 1.2429724789198933e-05, 6279: 1.8945871425126123e-05, 8372: 1.3963670529630206e-05, 10465: 2.1063120941708394e-05, 12558: 1.3487523319114239e-05, 14651: 1.6987522948670006e-05, 16744: 1.3984219649584469e-05, 18837: 1.4412476693989214e-05, 20930: 1.6676696282256086e-05, 23023: 1.567945102178449e-05, 25116: 1.6670825745944584e-05, 27209: 1.7515229116783503e-05, 29302: 1.7584954738753652e-05, 31395: 1.701027488147994e-05, 33488: 1.6526053467372417e-05, 35581: 1.669247867539525e-05, 37674: 1.8517613526297e-05, 39767: 2.1158532162598513e-05, 41860: 1.7886789549791484e-05, 43953: 1.6159081934105367e-05, 46046: 1.6832842658179888e-05, 48139: 1.8337063615235988e-05, 50232: 1.715908410164331e-05, 52325: 1.784238660998574e-05, 54418: 1.4138347234303525e-05, 56511: 1.7141468327389944e-05, 58604: 2.0007341523406977e-05, 60697: 1.851082512459487e-05, 62790: 1.8433944339257316e-05, 64883: 1.8018533245002458e-05, 66976: 1.708642150266865e-05, 69069: 2.329908257965511e-05, 71162: 1.7842017498653415e-05, 73255: 1.6829174507511866e-05, 75348: 1.7897614679478725e-05, 77441: 1.8998164760478593e-05, 79534: 1.8412110485444103e-05, 81627: 1.9121098806312597e-05, 83720: 1.8588257227263865e-05, 85813: 1.8352476897042825e-05, 87906: 1.959284402242084e-05, 89999: 1.2248990856486997e-05, 92092: 1.721467861239243e-05, 94185: 1.729357776172254e-05, 96278: 1.5201101318821994e-05, 98371: 1.809339513233222e-05, 100464: 1.7736696343390492e-05, 102557: 1.8811560184652107e-05, 104650: 2.1456881242573535e-05, 106743: 1.7849908535018426e-05, 108836: 2.0728623302260397e-05, 110929: 1.677192615157147e-05, 113022: 1.7166421150600692e-05, 115115: 1.9164402422349934e-05, 117208: 1.826275229761633e-05, 119301: 1.472311965916135e-05, 121394: 1.645211200870642e-05, 123487: 2.062036922850877e-05, 125580: 1.7297249757300278e-05, 127673: 1.3156881696894901e-05, 129766: 1.5385139203809818e-05, 131859: 1.6515596487790073e-05, 133952: 1.3884587785861361e-05, 136045: 1.576880640307561e-05, 138138: 1.4311375967953184e-05, 140231: 1.767009182687883e-05, 142324: 1.52888068066346e-05, 144417: 1.5164402937260242e-05, 146510: 1.6476696895418363e-05, 148603: 1.821926647557988e-05, 150696: 1.293743091182561e-05, 152789: 1.4541834836330162e-05, 154882: 1.4660550161786035e-05, 156975: 1.0468990225857551e-05, 159068: 1.8014311747745088e-05, 161161: 1.6552109245655186e-05, 163254: 1.6984588214529492e-05, 165347: 1.7213946263895395e-05, 167440: 1.688752421647857e-05, 169533: 1.663027444444255e-05, 171626: 1.8383486093867808e-05, 173719: 1.687357744731761e-05, 175812: 1.9531193138057484e-05, 177905: 1.759871609782407e-05, 179998: 1.6915595475071612e-05, 182091: 1.732972450554371e-05, 184184: 9.087523565106435e-06, 186277: 1.480000023089281e-05, 188370: 1.945119178127668e-05, 190463: 1.4295230658058454e-05, 192556: 1.724642218697235e-05, 194649: 1.5273210998419502e-05, 196742: 1.4593394648352074e-05, 198835: 1.5689540919292412e-05, 200928: 1.6304584531916663e-05, 203021: 1.598238387495416e-05, 205114: 1.5697245370733354e-05, 207207: 2.0592843626685645e-05, 209300: 1.4703484346081904e-05}}\n"
     ]
    }
   ],
   "source": [
    " # ADD YOUR TEST CODE HERE TO WORK ON REAL DATA\n",
    "import timeit\n",
    "import random\n",
    "import string\n",
    "\n",
    "HASH_KEYS = 5\n",
    "\n",
    "@staticmethod\n",
    "def txt_to_list(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        if (file_path == \"test-search.txt\") or (file_path == \"synthetic_test_search.txt\"):\n",
    "            return content.split(\"\\n\")\n",
    "        else:\n",
    "            return content.split()\n",
    "\n",
    "class ExperimentalFramework:\n",
    "    def __init__(self, data_file, data_structures_dict, operation_repeats=50, search_intervals=5, search_test_file=\"test-search.txt\"):\n",
    "        self.data_values = txt_to_list(data_file)\n",
    "        self.search_words = txt_to_list(search_test_file)\n",
    "        self.data_structures_dict = data_structures_dict\n",
    "        self.operation_repeats = operation_repeats\n",
    "        self.intervals = len(self.data_values) // search_intervals\n",
    "        self.insert_time = {}\n",
    "        self.mean_search_time = {}\n",
    "\n",
    "    def calc_insert_search_time_multiple_data_structures(self):\n",
    "        for data_structure_name, data_structure in self.data_structures_dict.items():\n",
    "            print(data_structure_name)\n",
    "            self.calc_insert_search_time_one_data_structure(data_structure_name, data_structure)\n",
    "\n",
    "    def calc_insert_search_time_one_data_structure(self, data_structure_name, data_structure):\n",
    "        self.insert_time[data_structure_name] = {}\n",
    "        self.mean_search_time[data_structure_name] = {}\n",
    "\n",
    "        for i, word in enumerate(self.data_values):\n",
    "            self.insert_time[data_structure_name][i] = timeit.timeit(lambda: data_structure.insertElement(word), number=self.operation_repeats)\n",
    "\n",
    "            if i % self.intervals == 0:\n",
    "                # Executes the search function in specified intervals for the data structure over the elements already input\n",
    "                search_time = [timeit.timeit(lambda: data_structure.searchElement(word), number=self.operation_repeats) for word in self.search_words]\n",
    "                self.mean_search_time[data_structure_name][i] = sum(search_time) / (self.operation_repeats * len(search_time))\n",
    "        print(f\"Mean Search Time - {self.mean_search_time}\")\n",
    "\n",
    "    def get_insert_search_time_one_data_structure(self):\n",
    "        return self.calc_insert_search_time_one_data_structure(list(data_structures_dict)[0], list(data_structures_dict.values())[0])\n",
    "\n",
    "\n",
    "class RunTests(ExperimentalFramework):\n",
    "\n",
    "    def __init__(self, data_file, data_structures_dict, operation_repeats=50, search_intervals=5, search_test_file=\"test-search.txt\"):\n",
    "        super().__init__(data_file, data_structures_dict, operation_repeats, search_intervals, search_test_file)\n",
    "\n",
    "    def sorted_real_data(self):\n",
    "        self.data_values = sorted(self.data_values)\n",
    "        self.calc_insert_search_time_multiple_data_structures()\n",
    "\n",
    "    def no_repeats_real_data(self):\n",
    "        self.data_values = set(self.data_values)\n",
    "        print(self.data_values)\n",
    "        self.calc_insert_search_time_multiple_data_structures()\n",
    "\n",
    "    def normal_real_data(self):\n",
    "        self.calc_insert_search_time_multiple_data_structures()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_structures_dict = {\"BST\": BinarySearchTreeSet()}\n",
    "    test = RunTests(\"test1-mobydick.txt\", data_structures_dict, 1, 100)\n",
    "    test.normal_real_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF\n",
      "Mean Search Time - {'BF': {0: 1.1083307232468404e-05, 1000: 1.3630089308421373e-05, 2000: 1.3276122864231717e-05, 3000: 1.3906893908311535e-05, 4000: 1.3283575441448965e-05, 5000: 1.419188816350099e-05, 6000: 1.0463742906092432e-05, 7000: 1.3725240162037855e-05, 8000: 1.1369061465088965e-05, 9000: 1.2196860342499846e-05, 10000: 5.9843574281178375e-06, 11000: 1.2999083820792882e-05, 12000: 1.2954703893762228e-05, 13000: 1.2959955336900646e-05, 14000: 1.3381966445647054e-05, 15000: 1.4834748568044528e-05, 16000: 1.3354782089226822e-05, 17000: 1.2139117308793454e-05, 18000: 1.229715091306404e-05, 19000: 6.092279335202951e-06, 20000: 1.2917552928976173e-05, 21000: 1.3219832531150493e-05, 22000: 1.3152134055844066e-05, 23000: 1.270620110730885e-05, 24000: 1.30410501460269e-05, 25000: 1.2973720752816211e-05, 26000: 1.3293162022077337e-05, 27000: 1.3130312920782153e-05, 28000: 1.3242044639591565e-05, 29000: 1.2831385318949485e-05, 30000: 1.3287240234801973e-05, 31000: 1.2816536382059229e-05, 32000: 1.2781966546571205e-05, 33000: 9.295541868550318e-06, 34000: 1.2778938564539539e-05, 35000: 1.3571754221507874e-05, 36000: 1.3075553130504139e-05, 37000: 1.3154413409312595e-05, 38000: 1.3020502913264589e-05, 39000: 1.2870055900407986e-05, 40000: 1.3025329512018482e-05, 41000: 1.316160909238391e-05, 42000: 1.3064815638087399e-05, 43000: 6.29505026804585e-06, 44000: 1.297967591031595e-05, 45000: 1.337094972555281e-05, 46000: 6.297240241862542e-06, 47000: 7.862279493382523e-06, 48000: 1.3056458045556808e-05, 49000: 1.34230055065836e-05, 50000: 7.039754125992013e-06, 51000: 1.3582715224838872e-05, 52000: 1.2760268174392801e-05, 53000: 1.3418714906083804e-05, 54000: 1.2940513997666496e-05, 55000: 1.3329095100494903e-05, 56000: 1.36162682863046e-05, 57000: 1.3441206729976075e-05, 58000: 1.3451575569537932e-05, 59000: 1.3081418869330147e-05, 60000: 1.3217340768497e-05, 61000: 1.043660326876454e-05, 62000: 1.286579891076759e-05, 63000: 1.2146860273950343e-05, 64000: 1.3251921809772707e-05, 65000: 1.3758480235382749e-05, 66000: 1.5570212255736718e-05, 67000: 1.3205352130049433e-05, 68000: 1.5832603403091348e-05, 69000: 1.3668335286130369e-05, 70000: 1.5823564273643426e-05, 71000: 1.5536011209680216e-05, 72000: 1.4943787639481978e-05, 73000: 1.3380223454636985e-05, 74000: 1.2996815601571895e-05, 75000: 1.1283072698913389e-05, 76000: 1.325035757156266e-05, 77000: 1.3683564185721581e-05, 78000: 1.4849854743774128e-05, 79000: 1.3297731889276531e-05, 80000: 1.3759653656301219e-05, 81000: 1.4888379884124136e-05, 82000: 1.3617150890042579e-05, 83000: 9.7257096786052e-06, 84000: 1.1549765489964262e-05, 85000: 1.1907173190578069e-05, 86000: 1.3117296035874989e-05, 87000: 1.3095910768883106e-05, 88000: 6.9785473982715075e-06, 89000: 1.6260446938972235e-05, 90000: 2.0268122950443924e-05, 91000: 8.07251396859533e-06, 92000: 9.595810093620386e-06, 93000: 1.5848994452776855e-05, 94000: 1.6677687107195153e-05, 95000: 1.229203346461141e-05, 96000: 1.6283083664170108e-05, 97000: 1.770787702628812e-05, 98000: 1.2178837917432938e-05, 99000: 1.3815296017798965e-05}}\n"
     ]
    }
   ],
   "source": [
    "# ADD YOUR TEST CODE HERE TO WORK ON SYNTHETIC DATA\n",
    "import timeit\n",
    "\n",
    "NUM_SYNTHETIC = 100000\n",
    "HASH_KEYS = 5\n",
    "\n",
    "def list_to_txt(list):\n",
    "    with open(\"synthetic_data.txt\", \"w\") as file:\n",
    "        for value in list:\n",
    "            file.write(value)\n",
    "            file.write('\\n')\n",
    "\n",
    "class SyntheticData(ExperimentalFramework):\n",
    "    def __init__(self, data_structures_dict, operation_repeats=50, search_intervals=5):\n",
    "        self.data_values = TestDataGenerator().generateData(NUM_SYNTHETIC)\n",
    "        list_to_txt(self.data_values)\n",
    "        self.data_file = \"synthetic_data.txt\"\n",
    "        self.search_test_file = \"synthetic_test_search.txt\"\n",
    "        super().__init__(self.data_file, data_structures_dict, operation_repeats, search_intervals, self.search_test_file)\n",
    "\n",
    "    def get_results(self):\n",
    "        self.calc_insert_search_time_multiple_data_structures()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_structures_dict = {\"BF\": BloomFilterSet(BITARRAY_SIZE, HASH_KEYS)}\n",
    "    test_synthetic = SyntheticData(data_structures_dict, 10, 100)\n",
    "    test_synthetic.get_results()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
